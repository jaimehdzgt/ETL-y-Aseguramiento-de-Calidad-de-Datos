# ETL-y-Aseguramiento-de-Calidad-de-Datos



# ETL & Data Quality for Eâ€‘commerce (Pedidos)

Proyecto completo para demostrar **buenas prÃ¡cticas de ETL y aseguramiento de calidad de datos** en un caso de eâ€‘commerce.
Incluye normalizaciÃ³n de esquema, limpieza, validaciones de negocio, deduplicaciÃ³n, correcciÃ³n geogrÃ¡fica, **KPIs** e **insights** con un reporte HTML estilizado.

> **TecnologÃ­as:** Python Â· Pandas Â· NumPy Â· Matplotlib Â· Google Colab

---

## ğŸ§­ Objetivo y Enunciado de Negocio

**Objetivo:** limpiar y estandarizar el registro de pedidos para habilitar anÃ¡lisis confiables de ventas, rentabilidad y logÃ­stica.

**Enunciado de negocio:** _â€œComo equipo de eâ€‘commerce queremos mejorar la rentabilidad y la experiencia de envÃ­o. Para ello necesitamos datos consistentes por pedido, producto, cliente y geografÃ­a; asÃ­ podremos detectar fugas de margen, optimizar modalidades de envÃ­o y priorizar categorÃ­as y segmentos de clientes.â€_

---

## ğŸ“‚ Estructura del repositorio

```
.
â”œâ”€â”€ etl_enhanced_colab.ipynb           # Notebook principal (listo para Google Colab)
â”œâ”€â”€ etl_cleaning_notebook_fixed.ipynb  # Variante previa (tambiÃ©n funcional)
â”œâ”€â”€ fact_orders_clean.csv              # Salida con datos limpios (se genera al ejecutar)
â”œâ”€â”€ quality_report.csv                 # Resumen de calidad (se genera al ejecutar)
â”œâ”€â”€ README.md                          # Este archivo
â””â”€â”€ /datasets/                         # (opcional local) lugar para .xlsx si trabajas fuera de Colab
```

---

## ğŸš€ EjecuciÃ³n rÃ¡pida (Google Colab)

1. Sube **`etl_enhanced_colab.ipynb`** a tu Colab o abre desde tu Drive.
2. En la secciÃ³n **Setup & Paths**, monta tu Drive y usa este `DATA_PATH` (segÃºn tu estructura en Drive):

```python
from google.colab import drive
drive.mount('/content/drive')

DATA_PATH = "/content/drive/MyDrive/Colab Notebooks/datasets/etl_dirty_orders.xlsx"
SHEET_RAW     = "raw_orders"
SHEET_STATES  = "lookup_states"
SHEET_SUBCATS = "lookup_subcats"
```

3. Ejecuta todas las celdas (Ctrl/Cmd + F9).  
   Al final tendrÃ¡s:
   - `fact_orders_clean.csv`
   - `quality_report.csv`
   - Un **reporte HTML** con KPIs e insights renderizado dentro del notebook.

> **Tip:** opcionalmente copia el Excel al runtime para lectura mÃ¡s rÃ¡pida:
>
> ```python
> !cp "/content/drive/MyDrive/Colab Notebooks/datasets/etl_dirty_orders.xlsx" "/content/etl_dirty_orders.xlsx"
> DATA_PATH = "/content/etl_dirty_orders.xlsx"
> ```

---

## ğŸ› ï¸ Pipeline de ETL (resumen)

1. **NormalizaciÃ³n de columnas**
   - Convierte nombres a `snake_case`; unifica variantes (`total_usd`â†’`total`, `order_id*`â†’`order_id` principal).
2. **RemociÃ³n de filas no-dato**  
   - Elimina `SUBTOTAL`, `TOTAL GENERAL`, etc., incluso si aparecen en cualquier columna.
3. **Parseo y tipificaciÃ³n**
   - **Fechas**: ISO, MDY, DMY y seriales de Excel (sin warnings de pandas).
   - **Moneda**: soporta sÃ­mbolos/formatos US/EU y textos como `incluido`.
   - **Porcentajes**: a fracciÃ³n [0â€“1].
4. **Limpieza de texto**
   - Trim, compresiÃ³n de espacios, `Title Case` en atributos clave; emails en minÃºsculas.
5. **Lookups / Diccionarios**
   - UnificaciÃ³n de **estados** y **subcategorÃ­as** mediante hojas `lookup_states` y `lookup_subcats`.
6. **Reglas de negocio**
   - `ship_date â‰¥ order_date`, `payment_date â‰¥ order_date`.
   - Recalculo de `total_calc` y flag de discrepancia vs `total`.
   - `qty â‰¥ 1` (flag en invÃ¡lidos).
7. **CorrecciÃ³n geogrÃ¡fica**
   - DetecciÃ³n e intercambio `lat/long` si estÃ¡n invertidos (valores dentro de MÃ©xico).
8. **DeduplicaciÃ³n robusta**
   - Llave (`order_id`, `productid`, `order_date`) tolerando **columnas duplicadas** por nombre.
9. **ExportaciÃ³n**
   - `fact_orders_clean.csv` + `quality_report.csv`.
10. **Insights**
    - GrÃ¡ficos rÃ¡pidos (ventas/utilidad por categorÃ­a, distribuciÃ³n de descuentos).
    - Reporte HTML con KPIs, segmentos, geografÃ­a, categorÃ­as, logÃ­stica y prÃ³ximos pasos.

---

## ğŸ“Š KPIs y mÃ©tricas calculadas

- **Ã“rdenes totales**
- **Ventas totales (`total`/`total_calc`)**
- **Utilidad total (`profit`)** y **Margen global** = Profit / Ventas
- **Tasa de Ã³rdenes rentables** = % de pedidos con `profit > 0`
- **Top segmentos** por conteo y por utilidad
- **Top regiones/estados** por utilidad
- **Top categorÃ­as/subcategorÃ­as** por ventas y utilidad
- **Modalidades de envÃ­o** (o proxy) por frecuencia y utilidad
- **Lead time** (dÃ­as): `ship_date âˆ’ order_date` *(si existen columnas)*
- **Tasa de devoluciones** *(si existe `order_status`)*
- **Flags de calidad**: fechas fuera de secuencia, discrepancias de total, cantidad invÃ¡lida, lat/lon invertidos

---

## ğŸ“‘ Diccionario bÃ¡sico de datos (esperado)

- `order_id` â€” Identificador del pedido.
- `order_date`, `ship_date`, `payment_date` â€” Fechas clave del ciclo del pedido.
- `productid`, `category`, `sub_category` â€” Identificadores y taxonomÃ­a de producto.
- `qty`, `unit_price`, `discount_pct`, `tax`, `shipping` â€” Componentes de precio.
- `total` / `total_calc` â€” Total reportado y recalculado.
- `profit` â€” Utilidad.
- `segment`, `region`, `state`, `city` â€” Atributos de cliente/ubicaciÃ³n.
- `payment_method`, `order_priority`, `order_status` â€” Atributos operativos.
- `latitude`, `longitude` â€” GeolocalizaciÃ³n (opcional).

> El notebook es tolerante a columnas faltantes: si alguna no existe, salta los cÃ¡lculos dependientes.

---

## ğŸ§ª Reproducibilidad & Calidad

- **Sin warnings** en parseo de fechas: no usa `infer_datetime_format`; emplea formatos explÃ­citos y seriales de Excel.
- **Regex sin `SyntaxWarning`**: usa `r'\s+'` para compresiÃ³n de espacios.
- **DeduplicaciÃ³n sin errores** con columnas repetidas (`order_id` duplicado por nombre).

---

## ğŸ§· Fragmentos Ãºtiles

**Quitar filas noâ€‘dato en cualquier columna**

```python
tokens = {"SUBTOTAL", "TOTAL GENERAL", "TOTAL_GENERAL"}
mask_bad = df.astype(str).apply(lambda s: s.str.strip().str.upper().isin(tokens)).any(axis=1)
df = df[~mask_bad].copy()
```

**DeduplicaciÃ³n robusta con llaves repetidas por nombre**

```python
import pandas as pd

keys_wanted = ['order_id', 'productid', 'order_date']

def first_series_by_name(df, name):
    idxs = [i for i, c in enumerate(df.columns) if c == name]
    return df.iloc[:, idxs[0]] if idxs else None

aux_cols, keys_present = {}, []
for k in keys_wanted:
    s = first_series_by_name(df, k)
    if s is not None:
        aux_cols[k] = s; keys_present.append(k)

if keys_present:
    df_keys = pd.DataFrame(aux_cols, index=df.index)
    order_idx = df_keys.sort_values(by=keys_present, kind='mergesort').index
    dup_mask = df_keys.loc[order_idx].duplicated(subset=keys_present, keep='first')
    df = df.loc[order_idx][~dup_mask].copy()
```

---

## ğŸ› SoluciÃ³n de problemas

- **`No se encontrÃ³ DATA_PATH`** â†’ Verifica la ruta del Excel o usa la copia al runtime (`/content/etl_dirty_orders.xlsx`).  
- **`column label 'order_id' is not unique`** â†’ Usa la deduplicaciÃ³n robusta (secciÃ³n anterior).  
- **Fechas con warnings** â†’ Garantiza que estÃ¡s usando la funciÃ³n `parse_date_series` del notebook mejorado.  
- **GrÃ¡ficas vacÃ­as** â†’ Revisa que existan las columnas usadas (el notebook crea â€œfallbacksâ€ cuando faltan).

---

## ğŸ“œ Licencia

Este proyecto es de uso educativo y demostrativo. Ãšsalo como base para tus propios procesos de limpieza y anÃ¡lisis.

---

## ğŸ‘‹ Contacto / AutorÃ­a

Si necesitas adaptar el pipeline a tu esquema real (nombres de columnas, reglas de negocio, lookups adicionales, dashboards), abre un issue o comenta en el notebook. Â¡Con gusto lo ajustamos!

